---
layout: post
title: "9. Dynamic Environments?"
mathjax: true
comments: true
description: ""
keywords: ""
---  

### 9.1 Environment

So far we have seen Greedy, Dijsktra, A\*, Weighted A\*, Backward A\*, and ARA\*. Each of these searches work only in static environments. But, in dynamic environments they won't work because the $g-value$ of nodes will change with change in environment. In **Figure 9.1**, we can see that changes in $g-values$ when the door closes.  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ![eg]({{ site.url }}/assets/images/env_change.PNG)  

<p align="center">
Figure 9.1 Change in environment
</p>



### 9.2 D* Lite and Anytime D*

There's a simple solution to this: update the $g-values$ using new sensory information. The robot finds a solution, executes it, and finds that the environment has changed; updates $g-values$ according to the environment, set current node to $s_{start}$ and replan. In simple terms, D\* repairs the search locally i.e. based on the information from sensors. 

![eg]({{ site.url }}/assets/images/dstar1.PNG)

Now, we can easily incorporate anytime algorithm with D\*. 
![eg]({{ site.url }}/assets/images/any_dstar.PNG)

### 9.3 Takeaways

### 9.4 References
[1]. 16-350 Planning Techniques for Robotics - [link](http://www.cs.cmu.edu/~maxim/classes/robotplanning/)
[2]. Choset H., Lynch K. M., Hutchinson S. Kantor G., Burgard W., Kavraki L. E., Thrun Sebastian. Principles of Robot Motion. MIT Press
